---
title: "Prediction about 2024 U.S. Presidential Election Outcome Using Linear Modeling"
subtitle: "My subtitle if needed"
author: 
  - Yunkai Gu
  - Anqi Xu
  - Yitong Wang
thanks: "Code and data are available at: [https://github.com/Kylie309/2024-US-election-prediction](https://github.com/Kylie309/2024-US-election-prediction)."
date: today
date-format: long
abstract: "This study aims to forecast the outcome of the 2024 U.S. Presidential Election using aggregated polling data and a linear modeling approach. The study also includes an analysis of a selected pollsterâ€™s methodology and an idealized survey design for forecasting elections within a limited budget."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)
library(ggplot2)
library(arrow)
```


# Introduction

The U.S. presidential election is a critical event that attracts substantial public and media interest. Various tools and methodologies have then been used for making predictions about the final electoral outcome.  
Curious about the election outcome as well, this paper employs the "poll-of-polls" approach to make predictions, which aggregates multiple polls to minimize biases and enhance prediction accuracy. A linear model is built to forecast the winner of the 2024 U.S. Presidential Election. In addition, in-depth analysis on certain pollster's methodology is also included, discussing their sampling approach, strengths, and weaknesses.

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.


Plot basic relationship


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Read data
trump_national_data <-
  read_parquet(
    file = here::here("data/02-analysis_data/trump_national_data.parquet")
    )
trump_state_data <-
  read_parquet(
    file = here::here("data/02-analysis_data/trump_state_data.parquet")
    )


```



## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.



# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].


## Model set-up


Define $y_i$ as the percentage vote for Trump. Then $x_{i1}$ is the sample size and $x_{i2}$ is the pollster. 

$$y_i = \alpha + \beta_i x_{i1} + \gamma_i x_{i2}$$

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}



### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false


spline_model_national <-
  readRDS(file = here::here("models/model_national.rds"))

spline_model_state <-
  readRDS(file = here::here("models/model_state.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of Trump Percentage Vote based on Sample Size and Pollster"
#| warning: false

modelsummary::modelsummary(
  list(
    "Model 1" = spline_model_national,
    "Model 2" = spline_model_state
  ),
  fmt = 2
)
```


Posterior predictive checks for national spline model:


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

pp_check(spline_model_national)
```


Posterior predictive checks for state spline model:


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

pp_check(spline_model_state)
```


Predict posterior draws and spline fit for votes nationally


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Predict and plot
# Create new data for prediction
new_data_national <- data.frame(
  end_date_num = seq(
    min(trump_national_data$end_date_num),
    max(trump_national_data$end_date_num),
    length.out = 100
  )
)

# Predict posterior draws
posterior_preds_national <- posterior_predict(spline_model_national, 
                                     newdata = new_data_national)

# Summarize predictions
pred_summary_national <- new_data_national |>
  mutate(
    pred_mean = colMeans(posterior_preds_national),
    pred_lower = apply(posterior_preds_national, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds_national, 2, quantile, probs = 0.975)
  )

# Plot the spline fit
ggplot(trump_national_data, aes(x = end_date_num, y = pct)) +
  geom_point() +
  geom_line(
    data = pred_summary_national,
    aes(x = end_date_num, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary_national,
    aes(x = end_date_num, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "Number of Days Since Half a Year Before Election",
    y = "Vote Percentage for Trump",
    title = "Poll Percentage of Trump over Time with Spline Fit"
  ) +
  theme_minimal()
```


Predict posterior draws and spline fit for votes in each state


```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Change 'pollster' and 'state' to factor variables
trump_state_data <- trump_state_data |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

# Predict and plot
# Create new data for prediction
new_data_state <- expand.grid(
  end_date_num = seq(
    min(trump_state_data$end_date_num),
    max(trump_state_data$end_date_num),
    length.out = 100
  ),
  state = levels(trump_state_data$state)  # Include all states
)

# Predict posterior draws
posterior_preds_state <- posterior_predict(spline_model_state, 
                                              newdata = new_data_state)

# Summarize predictions
pred_summary_state <- new_data_state |>
  mutate(
    pred_mean = colMeans(posterior_preds_state),
    pred_lower = apply(posterior_preds_state, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds_state, 2, quantile, probs = 0.975)
  )

# Plot the spline fit
ggplot(trump_state_data, aes(x = end_date_num, y = pct, color = state)) +
  geom_point() +
  geom_line(data = pred_summary_state, 
            aes(x = end_date_num, y = pred_mean, group = state), 
            color = "blue") +
  labs(
    x = "Number of Days Since Half a Year Before Election",
    y = "Vote Percentage for Trump",
    title = "Poll Percentage of Trump over Time with Spline Fit"
  ) +
  theme_minimal() +
  facet_wrap(~ state, scales = "free_y") +  # Faceting by state
  theme(
    strip.text = element_text(size = 7), # Title size for each facet
    axis.text = element_text(size = 5), # Axis text size
    legend.text = element_text(size = 5),  # Adjust legend text size
    legend.title = element_text(size = 5),  # Adjust legend title size
    legend.key.size = unit(0.5, "cm"),  # Adjust size of legend keys
    legend.position = "right"  # Position legend to the right
  )
```


# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

#pp_check(first_model) +
#  theme_classic() +
#  theme(legend.position = "bottom")

#posterior_vs_prior(first_model) +
#  theme_minimal() +
#  scale_color_brewer(palette = "Set1") +
#  theme(legend.position = "bottom") +
#  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

#plot(first_model, "trace")

#plot(first_model, "rhat")
```



\newpage


# References


